{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo práctico N° 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para los siguientes ejercicios vamos a usar el Wisconsin Breast Cancer dataset, construído a partir de imágenes digitalizadas. Las mismas describen la información obtenida de cada imagen de célula mamaria biopsiada, especificando si el diagnóstico sobre la misma es que es benigna o maligna.\n",
    "\n",
    "Se pide:\n",
    "\n",
    "1. Declarar una variable random_state igual al número de alumno en la hoja de cálculo \"Entregas TPs\" en el Google Drive de la materia.\n",
    "2. Implementar un clasificador kNN.\n",
    "3. Aplicarle z-score standarization a los datos. Dividir en conjunto de train y test y entrenar el clasificador con el sub-conjunto de datos de entrenamiento, mostrando la correspondiente tasa de aciertos. Utilizar el respectivo random_state.\n",
    "4. Considere el caso donde un incorrecto diagnóstico de cáncer cuando la célula es benigna tiene un costo de 5, mientras que una errónea omisión de una célula maligna tiene un costo de 20. Modificar las salidas del clasificador para que el mismo realice la mayor reducción posible del costo por errores de clasificación, e imprimir dichas salidas. Ayuda: una forma es utilizar el método *predicted_proba()* para obtener las probabilidades.\n",
    "5. Considerando el punto anterior, ampliar el código para que seleccione automáticamente o mediante iteraciones la cantidad de vecinos que minimiza el costo de un error de predicción. Especificar cuál es el costo mínimo obtenido tras dicha minimización.\n",
    "\n",
    "Fecha de entrega: **17/05/2017**.\n",
    "\n",
    "Nota: la resolución de los ejercicios es **individual**; en el caso de que dos ejercicios enviados contengan un código igual o muy similar (sin considerar los comentarios), se los considerará a ambos como desaprobados. La reutilización del código del notebook está permitida (por ejemplo para confeccionar gráficos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desarrollo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Se declara la variable random_state con el numero de alumno correspondiente (3) y se instancia el dataset breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], \n",
       "      dtype='<U9')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "semilla = np.random.RandomState(3)\n",
    "data = load_breast_cancer()\n",
    "x = data.data\n",
    "y = data.target\n",
    "data.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Se Implementa un clasificador kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "clf = neighbors.KNeighborsClassifier(weights='distance', n_neighbors=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Se aplica z-score standarization a los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy import stats\n",
    "x_norm = stats.zscore(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se divide en conjunto de train y test y entrenar el clasificador con el sub-conjunto de datos de entrenamiento. Luego se muestra la tasa de aciertos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de aciertos en la clasificación:  0.947368421053\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_norm, y, random_state=semilla, test_size=0.2)\n",
    "clf.fit(X_train, y_train)\n",
    "print('Tasa de aciertos en la clasificación: ', clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Se establecen los costos de lfn y lfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lfn = 20\n",
    "lfp = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se define una funcion que modifica las salidas del clasificador teniendo en cuenta los costos definidos anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predecir(X_test, lfn, lfp):\n",
    "    c = lfn / lfp\n",
    "    y_hat_proba = clf.predict_proba(X_test)\n",
    "    y_hat = []\n",
    "    for i in range(0, len(y_hat_proba)):\n",
    "        # P(y=1∣x)>(1/c) * P(y=0∣x)\n",
    "        if y_hat_proba[i, 1] > ((1 / c) * y_hat_proba[i, 0]):\n",
    "            y_hat.append(1)\n",
    "        else:\n",
    "            y_hat.append(0)\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se predice y se muestra la salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La salida de la prediccion es: \n",
      " [1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "y_hat = predecir(X_test, lfn, lfp)\n",
    "print('La salida de la prediccion es: \\n', y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se muestran los errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicho 0</th>\n",
       "      <th>Predicho 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Real 0</th>\n",
       "      <td>33</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real 1</th>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Predicho 0  Predicho 1\n",
       "Real 0          33           7\n",
       "Real 1           0          74"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import pandas\n",
    "# Creamos la confusion matrix y le asignamos las filas y columnas correspondientes\n",
    "cm = metrics.confusion_matrix(y_test, y_hat, labels=[0,1])\n",
    "list1 = [\"Real 0\", \"Real 1\"]\n",
    "list2 = [\"Predicho 0\", \"Predicho 1\"]\n",
    "pandas.DataFrame(cm, list1, list2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Se busca el numero de vecinos $k$ que de el menor costo posible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El k optimo es:  1 . Da un costo de:  60\n"
     ]
    }
   ],
   "source": [
    "k_optimo = 0 \n",
    "costo_optimo = 'inicial'\n",
    "for k in range(1, len(X_train)):\n",
    "    clf = neighbors.KNeighborsClassifier(weights='distance', n_neighbors=k)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_hat = predecir(X_test, lfn, lfp)\n",
    "    cm = metrics.confusion_matrix(y_test, y_hat, labels=[0,1])\n",
    "    total = cm[0][1] * 20 + cm[1][0] * 5\n",
    "    if costo_optimo == 'inicial':\n",
    "        costo_optimo = total\n",
    "        k_optimo = k\n",
    "    else:\n",
    "        if total < costo_optimo:\n",
    "            costo_optimo = total\n",
    "            k_optimo = k\n",
    "   # print('k:', k, 'total:', total)\n",
    "   # print('ko:', k_optimo, 'costo:', costo_optimo)\n",
    "   # print(cm)\n",
    "    \n",
    "print('El k optimo es: ', k_optimo, '. Da un costo de: ', costo_optimo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
